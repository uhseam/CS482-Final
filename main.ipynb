{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Depth Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import time\n",
    "\n",
    "# Load the images\n",
    "def load_image_gray(filepath):\n",
    "    \"\"\"Loads an image into a numpy array.\n",
    "    Note: image will have 3 color channels [r, g, b].\"\"\"\n",
    "    img = Image.open(filepath)\n",
    "    img = np.asarray(img).astype(float)/255\n",
    "    if len(img.shape) > 2:\n",
    "        return img[:, :, 0]\n",
    "    else:\n",
    "        return img\n",
    "    \n",
    "# Get image patches\n",
    "def get_patch(image, x, y, patch_half_width):\n",
    "    return image[y-patch_half_width:y+patch_half_width+1,\n",
    "                 x-patch_half_width:x+patch_half_width+1]\n",
    "\n",
    "def patch_match_stereo(image_a, image_b, x_a, y_a,\n",
    "                       match_score_fn,\n",
    "                       patch_half_width=9):\n",
    "    \"\"\"Returns the location of a feature/patch between stereo images.\n",
    "    Inputs are the x, y coordinates of the patch in image_a.\n",
    "    Outputs are the x, y coordinates of the patch in image_b.\"\"\"\n",
    "\n",
    "    # (1) Get the patch in image a\n",
    "    patch_a = get_patch(image_a, x_a, y_a, \n",
    "                        patch_half_width=patch_half_width)\n",
    "    \n",
    "    # (2) Compute the responses along the epipolar line in image b\n",
    "    # Define the possible coordinates along with the match might be found\n",
    "    # (You should feel free to modify this code if you have a simpler\n",
    "    # way to represent this operation.)\n",
    "    possible_coordinates = [(x, y_a) for x in range(patch_half_width, image_b.shape[1] - patch_half_width)]\n",
    "\n",
    "    if possible_coordinates is None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    response = np.zeros((len(possible_coordinates)))\n",
    "    for ind, (x_b, y_b) in enumerate(possible_coordinates):\n",
    "        # Get the patch\n",
    "        patch_b = get_patch(image_b, x_b, y_b,\n",
    "                            patch_half_width=patch_half_width)\n",
    "        # Compute the match score & store\n",
    "        response[ind] = match_score_fn(patch_a, patch_b)\n",
    "    \n",
    "    # (3) Compute the maximum response\n",
    "    ind = np.argmax(response)\n",
    "    x_b, y_b = possible_coordinates[ind]\n",
    "\n",
    "    return x_b, y_b, response[ind]\n",
    "\n",
    "def compute_depth_map(image_a, image_b, match_score_fn, phw=8, spacing=15):\n",
    "    stime = time.time()\n",
    "    xs = range(phw, image_b.shape[1]-phw, spacing)\n",
    "    ys = range(phw, image_b.shape[0]-phw, spacing)\n",
    "    disparity_mat = np.zeros((len(ys), len(xs)))\n",
    "    responses_mat = np.zeros((len(ys), len(xs)))\n",
    "    for xi, x_a in enumerate(xs):\n",
    "        print(f\"Progress: {xi}/{len(xs)}\")\n",
    "        for yi, y_a in enumerate(ys):\n",
    "            x_b, y_b, response = patch_match_stereo(\n",
    "                image_a, image_b, x_a, y_a, match_score_fn, patch_half_width=phw)\n",
    "            dx = x_a - x_b\n",
    "            dy = y_a - y_b\n",
    "            disparity_mat[yi, xi] = np.sqrt(dx**2 + dy**2)\n",
    "            responses_mat[yi, xi] = response\n",
    "\n",
    "    # Compute and threshold the depth map\n",
    "    depth = 1/(disparity_mat.copy() + 1e-5)\n",
    "    depth[depth > 0.01] = 0.01\n",
    "    \n",
    "    print(f\"Time took: {time.time() - stime}\")\n",
    "    return depth\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Implemention of the Zero Normalized Cross Correlation algorithm\n",
    "for computing depth map\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "patch_a: first image patch\n",
    "patch_b: second image patch\n",
    "\n",
    "Returns\n",
    "----------\n",
    "z: numpy.ndarray\n",
    "        The image, of the same size as the derivatives, of estimated depths\n",
    "        at each point\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def compute_match_score_zncc(patch_a, patch_b):\n",
    "    # Compute mean of each patch\n",
    "    mean_a = np.mean(patch_a)\n",
    "    mean_b = np.mean(patch_b)\n",
    "\n",
    "    \n",
    "    # Compute normalized cross-correlation\n",
    "    numerator = np.sum((patch_a - mean_a) * (patch_b - mean_b))\n",
    "    sigmas = np.sqrt(np.sum((patch_a - mean_a)**2)) * np.sqrt(np.sum((patch_b - mean_b)**2))\n",
    "    \n",
    "    if sigmas == 0:  # Avoid division by zero\n",
    "        return 0.0\n",
    "    else:\n",
    "        zncc = numerator / sigmas\n",
    "        return zncc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load static parameters manually\n",
    "\n",
    "# load intrinsic camera matrices\n",
    "ip = np.array([[2759.48, 0,       1520.69],\n",
    "               [0,       2764.16, 1006.81],\n",
    "               [0,       0,       1      ]])\n",
    "\n",
    "\n",
    "# load external parameters of camera\n",
    "ep_10 = np.array([[0.70735,   0.706534,   0.0215749 ],\n",
    "                  [0.0218279, -0.0523403, 0.998391  ],\n",
    "                  [0.706526,  -0.705741 , -0.0524451]])\n",
    "ep_09 = np.array([[0.84137,    0.540262,   0.0145864 ],\n",
    "                  [0.00860137, -0.0403709, 0.999148  ],\n",
    "                  [0.540391,   -0.840528,  -0.0386139]])\n",
    "ep_08 = np.array([[0.928942,    0.370116,   0.00895096 ],\n",
    "                  [0.000956298, -0.0265758, 0.999646   ],\n",
    "                  [0.370223,    -0.928605,  -0.0250414 ]]) \n",
    "ep_07 = np.array([[0.995535,   0.0943815, -0.00170578],\n",
    "                  [0.003721,  -0.02118,   0.999769   ],\n",
    "                  [0.0943235, -0.995311,  -0.0214366 ]])\n",
    "ep_06 = np.array([[0.994915,    -0.100715,  0.00117536],\n",
    "                  [-0.00462005, -0.0339759, 0.999412  ],\n",
    "                  [-0.100616,   -0.994335,  -0.0342684]])\n",
    "ep_05 = np.array([[0.962742,   -0.270399,  0.00344709],\n",
    "                  [-0.0160548, -0.0444283, 0.998884  ],\n",
    "                  [-0.269944,  -0.961723,  -0.0471142]])\n",
    "ep_04 = np.array([[0.890856,   -0.454283,  -0.00158434],\n",
    "                  [-0.0211638, -0.0449857, 0.998763   ],\n",
    "                  [-0.453793,  -0.889721,  -0.0496901 ]])\n",
    "ep_03 = np.array([[0.795163,  -0.606377,  -0.00477103],\n",
    "                  [-0.050195, -0.0736593, 0.996019   ],\n",
    "                  [-0.604314, -0.791759,  -0.0890082 ]])\n",
    "ep_02 = np.array([[0.666779,   -0.74495,   0.021334  ],\n",
    "                  [-0.0831384, -0.0459057, 0.99548   ],\n",
    "                  [-0.740603,  -0.665539 , -0.0925429]])\n",
    "ep_01 = np.array([[0.582226,   -0.813027,  -0.000148752],\n",
    "                  [-0.0983866, -0.0706383, 0.992638    ],\n",
    "                  [-0.807052,  -0.577925,  -0.121118   ]])\n",
    "ep_00 = np.array([[0.450927,   -0.892535,  0.00679989],\n",
    "                  [-0.0945642, -0.0401974, 0.994707  ],\n",
    "                  [-0.887537,  -0.449183 , -0.102528 ]])\n",
    "\n",
    "# load camera positions\n",
    "cmpos_10 = np.array([-21.9937, -5.82033, -0.0463931])\n",
    "cmpos_09 = np.array([-20.9553, -4.61897, -0.0303931])\n",
    "cmpos_08 = np.array([-19.6309, -3.81958, -0.00781603])\n",
    "cmpos_07 = np.array([-17.6302, -3.36186, 0.0325247])\n",
    "cmpos_06 = np.array([-15.8818, -3.15083, 0.0592619])\n",
    "cmpos_05 = np.array([-14.1604, -3.32084, 0.0862032])\n",
    "cmpos_04 = np.array([-12.404,  -3.81315, 0.110559 ])\n",
    "cmpos_03 = np.array([-10.8142, -4.53704, 0.122293 ])\n",
    "cmpos_02 = np.array([-9.46627, -5.58174, 0.147736 ])\n",
    "cmpos_01 = np.array([-8.31326, -6.3181,  0.16107  ])\n",
    "cmpos_00 = np.array([-7.28137, -7.57667, 0.204446 ])\n",
    "\n",
    "# load picture resolution\n",
    "resolution = (3072, 2048)\n",
    "\n",
    "# load 3D bounds\n",
    "bound_10 = ((-20.6108, -7.91985), (-21.9686, -8.77828), (-3.49947, 1.71626))\n",
    "bound_09 = ((-20.6108, -7.91985), (-21.9686, -8.77828), (-3.49947, 1.71626))\n",
    "bound_08 = ((-20.9042, -9.85972), (-21.68  , -8.77828), (-6.68267, 1.71626))\n",
    "bound_07 = ((-21.0826, -12.6952), (-12.6362, -8.77828), (-3.82552, 1.67881))\n",
    "# wrong bound above\n",
    "bound_06 = ((-20.6108, -7.91985), (-21.9686, -8.77828), (-3.49947, 1.71626))\n",
    "bound_05 = ((-20.9042, -9.85972), (-21.68  , -8.77828), (-6.68267, 1.71626))\n",
    "bound_04 = ((-21.0826, -12.6952), (-12.6362, -8.77828), (-3.82552, 1.67881))\n",
    "# wrong bound below\n",
    "bound_03 = ((-20.6108, -7.91985), (-21.9686, -8.77828), (-3.49947, 1.71626))\n",
    "bound_02 = ((-20.9042, -9.85972), (-21.68  , -8.77828), (-6.68267, 1.71626))\n",
    "bound_01 = ((-21.0826, -12.6952), (-12.6362, -8.77828), (-3.82552, 1.67881))\n",
    "bound_00 = ((-21.0826, -12.6952), (-12.6362, -8.77828), (-3.82552, 1.67881))\n",
    "\n",
    "# cord for testing\n",
    "cord = (-15.0744, -11.9719, -1.79769)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images\n",
    "\n",
    "img0 = load_image_gray('fountain_dense_images/0000.png')\n",
    "img1 = load_image_gray('fountain_dense_images/0001.png')\n",
    "img2 = load_image_gray('fountain_dense_images/0002.png')\n",
    "img3 = load_image_gray('fountain_dense_images/0003.png')\n",
    "img4 = load_image_gray('fountain_dense_images/0004.png')\n",
    "img5 = load_image_gray('fountain_dense_images/0005.png')\n",
    "img6 = load_image_gray('fountain_dense_images/0006.png')\n",
    "img7 = load_image_gray('fountain_dense_images/0007.png')\n",
    "img8 = load_image_gray('fountain_dense_images/0008.png')\n",
    "img9 = load_image_gray('fountain_dense_images/0009.png')\n",
    "img10 = load_image_gray('fountain_dense_images/0010.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
